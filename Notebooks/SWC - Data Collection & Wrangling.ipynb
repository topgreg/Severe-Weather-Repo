{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4102f31",
   "metadata": {},
   "source": [
    "# Severe Weather Capstone - Data Collection & Wrangling\n",
    "\n",
    "Greg Welliver   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba529c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries and packages.\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.api import abline_plot\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model, preprocessing \n",
    "import warnings\n",
    "from scipy import stats\n",
    "import re\n",
    "from glob import glob, iglob\n",
    "from datetime import datetime\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d44e420",
   "metadata": {},
   "source": [
    "file location for downloads: \n",
    "    https://www.ncei.noaa.gov/pub/data/swdi/stormevents/csvfiles/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf95157",
   "metadata": {},
   "source": [
    "## Data Collection\n",
    "\n",
    "- storm files were collected from the Iowa Environmental Mesonet: https://mesonet.agron.iastate.edu/nws/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d322777",
   "metadata": {},
   "source": [
    "### working code, make markdown for now\n",
    "### All annual storm data files are saved on my local machine.  This code gathers all of the files and combines them into one file.\n",
    "filenames = glob('../Data/*.csv')\n",
    "print(\"There is a total of {} files.\".format(len(filenames)))\n",
    "\n",
    "target_path = '../Data/all_storm_data.csv'\n",
    "\n",
    "try:\n",
    "    # Read in Summary File is exists\n",
    "    all_storm_data = pd.read_csv(target_path)\n",
    "except:\n",
    "    # Read in all Subfiles\n",
    "    storm_data = [pd.read_csv(filepath) for filepath in filenames]\n",
    "    all_storm_data = pd.concat(storm_data)\n",
    "    \n",
    "    # Create Summary File for faster processing\n",
    "    hot100_all.to_csv(target_path,index=False)\n",
    "\n",
    "print(\"The total number of observations is {}.\".format(len(all_storm_data)))\n",
    "all_storm_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53f332f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "892bc82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "#df = pd.read_csv(\"../Data/StormEvents_details-ftp_v1.0_d2001_c20220425.csv\")\n",
    "#df = pd.read_parquet(\"../Data/all_storm_data.pqt\")\n",
    "#df = pd.read_csv(\"../Data/all_storm_data4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1b3f0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bb2c033",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b4bb053",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "451201e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74717770",
   "metadata": {},
   "source": [
    "for row in df[\"STATE_FIPS\"][:10]:\n",
    "    res = row.split(\".\", 1)[0]\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a31655d",
   "metadata": {},
   "source": [
    "# WORKING, MARKDOWN UNTIL FINAL\n",
    "# drop unnecessary columns\n",
    "df.drop(['CATEGORY', 'DATA_SOURCE', 'BEGIN_RANGE', 'BEGIN_AZIMUTH', 'BEGIN_LOCATION', 'END_RANGE', 'END_AZIMUTH', 'END_LOCATION', 'TOR_OTHER_WFO', 'TOR_OTHER_CZ_STATE', 'TOR_OTHER_CZ_FIPS', 'TOR_OTHER_CZ_NAME', 'CZ_TIMEZONE', 'WFO', 'CZ_TYPE', 'DAMAGE_CROPS'\n",
    "], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51d02f7",
   "metadata": {},
   "source": [
    "# WORKING, MARKDOWN UNTIL FINAL\n",
    "df['STATE_FIPS'] = df['STATE_FIPS'].astype(object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4eaadae",
   "metadata": {},
   "source": [
    "# WORKING, MARKDOWN UNTIL FINAL\n",
    "# Columns to replace nulls with NA:\n",
    "cols_na = ['EVENT_NARRATIVE', 'EPISODE_NARRATIVE', 'BEGIN_LAT', 'BEGIN_LON', 'END_LAT', 'END_LON', 'TOR_F_SCALE', 'MAGNITUDE_TYPE', 'FLOOD_CAUSE', 'STATE', 'STATE_FIPS']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7dcaf1",
   "metadata": {},
   "source": [
    "for x in cols_na:\n",
    "    print(df[x].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc1a6d1",
   "metadata": {},
   "source": [
    "# WORKING, MARKDOWN UNTIL FINAL\n",
    "for x in cols_na:\n",
    "    df[x] = df[x].fillna('NA')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca91def",
   "metadata": {},
   "source": [
    "for x in cols_na:\n",
    "    print(df[x].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380fcdc8",
   "metadata": {},
   "source": [
    "# WORKING, MARKDOWN UNTIL FINAL\n",
    "# Columns to replace nulls with 0:\n",
    "\n",
    "cols_0 = ['MAGNITUDE', 'TOR_LENGTH', 'TOR_WIDTH', 'DAMAGE_PROPERTY', 'INJURIES_DIRECT', 'INJURIES_INDIRECT', 'DEATHS_DIRECT', 'DEATHS_INDIRECT']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae92a6e",
   "metadata": {},
   "source": [
    "for x in cols_0:\n",
    "    print(df[x].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d8ca7c",
   "metadata": {},
   "source": [
    "# WORKING, MARKDOWN UNTIL FINAL\n",
    "for x in cols_0:\n",
    "    df[x] = df[x].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c336a4c",
   "metadata": {},
   "source": [
    "for x in cols_0:\n",
    "    print(df[x].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dea7af28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79757668",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e05c301",
   "metadata": {},
   "source": [
    "# WORKING, MARKDOWN UNTIL FINAL\n",
    "# remove NA values from state FIPS\n",
    "df = df[df['STATE_FIPS'] != \"NA\"].reset_index()\n",
    "\n",
    "# convert STATE_FIPS to INT so can use it for lookup later\n",
    "for x in df['STATE_FIPS']:\n",
    "    x = int(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb112f5c",
   "metadata": {},
   "source": [
    "df['STATE_FIPS'] = df['STATE_FIPS'].astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a706dac0",
   "metadata": {},
   "source": [
    "df['STATE_FIPS'] = df['STATE_FIPS'].astype(object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1111404f",
   "metadata": {},
   "source": [
    "df['STATE_FIPS']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46e4eda",
   "metadata": {},
   "source": [
    "df['CZ_FIPS'] = df['CZ_FIPS'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25161b5",
   "metadata": {},
   "source": [
    "df['CZ_FIPS']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdb63c7",
   "metadata": {},
   "source": [
    "df['CZ_FIPS'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "179e9f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[249750:249760]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb56f1d",
   "metadata": {},
   "source": [
    "df['CZ_FIPS'][249750:249760]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e561bc7",
   "metadata": {},
   "source": [
    "# WORKING, MARKDOWN UNTIL FINAL\n",
    "# add \"0\" or \"00\" to CZ FIPS so that it can be used to match later\n",
    "for i in (range(len(df['CZ_FIPS']))):\n",
    "    if len(df['CZ_FIPS'][i]) == 2:\n",
    "#        df['CZ_FIPS'][i] = df['CZ_FIPS'][i].astype(str)\n",
    "        df['CZ_FIPS'][i] = \"0\" + df['CZ_FIPS'][i]\n",
    "#        print(df['CZ_FIPS'][i])\n",
    "    elif len(df['CZ_FIPS'][i]) == 1:\n",
    "        df['CZ_FIPS'][i] = \"00\" + df['CZ_FIPS'][i]\n",
    "#        print(df['CZ_FIPS'][i])\n",
    "#     else:\n",
    "#         row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617cee30",
   "metadata": {},
   "source": [
    "df['STATE_FIPS'] = df['STATE_FIPS'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faea6473",
   "metadata": {},
   "source": [
    "# WORKING, MARKDOWN UNTIL FINAL\n",
    "# add \"0\" to state FIPS so that it can be used to match later\n",
    "for i in (range(len(df['STATE_FIPS']))):\n",
    "    if len(df['STATE_FIPS'][i]) == 1:\n",
    "#        df['CZ_FIPS'][i] = df['CZ_FIPS'][i].astype(str)\n",
    "        df['STATE_FIPS'][i] = \"0\" + df['STATE_FIPS'][i]\n",
    "#        print(df['CZ_FIPS'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1820db35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[\"CZ_FIPS\"] = df.apply(lambda x: \"0\" + x if len(x) == 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4206727e",
   "metadata": {},
   "source": [
    "# WORKING, MARKDOWN UNTIL FINAL\n",
    "# concatenate STATE FIPS and CZ FIPS into one column so that it can be used to match\n",
    "df['ST_CT_FIPS'] = df['STATE_FIPS'].astype(str) + df['CZ_FIPS'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18f967f",
   "metadata": {},
   "source": [
    "# WORKING, MARKDOWN UNTIL FINAL\n",
    "# remove all of the K's, M's, and B's in the DAMAGE_PROPERTY column and multiply them by appropriate values\n",
    "d = {r\"(\\d)K$\": r\"\\1*1000\", r\"M$\": r\"*1000000\", r\"B$\": r\"*1000000000\", r\"^K$\": r\"1000\"}\n",
    "\n",
    "#r stands for raw string\n",
    "#dollar is end of the line\n",
    "\n",
    "# for every key and value, run this code\n",
    "for k,v in d.items():\n",
    "     df[\"DAMAGE_PROPERTY\"] = df[\"DAMAGE_PROPERTY\"].str.replace(k, v, regex=True).fillna(\"0.0\")\n",
    "#df[\"DAMAGE_PROPERTY\"].apply(eval)\n",
    "df[\"DAMAGE_PROPERTY\"] = df[\"DAMAGE_PROPERTY\"].apply(eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4018c29e",
   "metadata": {},
   "source": [
    "# WORKING, MARKDOWN UNTIL FINAL\n",
    "# convert date strings to datetimes\n",
    "df['BEGIN_DATE_TIME'] =  pd.to_datetime(df['BEGIN_DATE_TIME'])\n",
    "df['END_DATE_TIME'] =  pd.to_datetime(df['END_DATE_TIME'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029661c1",
   "metadata": {},
   "source": [
    "# WORKING, MARKDOWN UNTIL FINAL\n",
    "# calculate duration of storm\n",
    "df['DURATION'] = df['END_DATE_TIME'] - df['BEGIN_DATE_TIME']\n",
    "\n",
    "# convert storm duration to minutes\n",
    "for i in (range(len(df['DURATION']))):\n",
    "    df['DURATION'][i] = df['DURATION'][i].total_seconds() / 60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b0a891",
   "metadata": {},
   "source": [
    "## Part 2 start here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97ba7134",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data\n",
    "# df = pd.read_csv(\"../Data/all_storm_data4.csv\", index_col=[0])\n",
    "# df.drop(['index'], axis=1, inplace=True)\n",
    "df = pd.read_parquet(\"../Data/all_storm_data6.pqt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d686f1bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BEGIN_YEARMONTH</th>\n",
       "      <th>BEGIN_DAY</th>\n",
       "      <th>BEGIN_TIME</th>\n",
       "      <th>END_YEARMONTH</th>\n",
       "      <th>END_DAY</th>\n",
       "      <th>END_TIME</th>\n",
       "      <th>EPISODE_ID</th>\n",
       "      <th>EVENT_ID</th>\n",
       "      <th>STATE</th>\n",
       "      <th>STATE_FIPS</th>\n",
       "      <th>...</th>\n",
       "      <th>TOR_LENGTH</th>\n",
       "      <th>TOR_WIDTH</th>\n",
       "      <th>BEGIN_LAT</th>\n",
       "      <th>BEGIN_LON</th>\n",
       "      <th>END_LAT</th>\n",
       "      <th>END_LON</th>\n",
       "      <th>EPISODE_NARRATIVE</th>\n",
       "      <th>EVENT_NARRATIVE</th>\n",
       "      <th>ST_CT_FIPS</th>\n",
       "      <th>DURATION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202202</td>\n",
       "      <td>20</td>\n",
       "      <td>2118</td>\n",
       "      <td>202202</td>\n",
       "      <td>20</td>\n",
       "      <td>2218</td>\n",
       "      <td>165464</td>\n",
       "      <td>999902</td>\n",
       "      <td>NEVADA</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Strong winds increased ahead of an approaching...</td>\n",
       "      <td>Station (UP994) 3.1 SE West Wendover, Elevatio...</td>\n",
       "      <td>32033</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202202</td>\n",
       "      <td>21</td>\n",
       "      <td>800</td>\n",
       "      <td>202202</td>\n",
       "      <td>22</td>\n",
       "      <td>1000</td>\n",
       "      <td>165465</td>\n",
       "      <td>999903</td>\n",
       "      <td>NEVADA</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A low centered over northern and central Nevad...</td>\n",
       "      <td>Thirteen inches fell at station (BCSN2) Big Cr...</td>\n",
       "      <td>32037</td>\n",
       "      <td>1560.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202202</td>\n",
       "      <td>22</td>\n",
       "      <td>200</td>\n",
       "      <td>202202</td>\n",
       "      <td>22</td>\n",
       "      <td>900</td>\n",
       "      <td>165465</td>\n",
       "      <td>999904</td>\n",
       "      <td>NEVADA</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A low centered over northern and central Nevad...</td>\n",
       "      <td>Fifteen inches fell at station (TJMN2) Toe Jam...</td>\n",
       "      <td>32031</td>\n",
       "      <td>420.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202202</td>\n",
       "      <td>18</td>\n",
       "      <td>1609</td>\n",
       "      <td>202202</td>\n",
       "      <td>18</td>\n",
       "      <td>1609</td>\n",
       "      <td>165611</td>\n",
       "      <td>1001181</td>\n",
       "      <td>ATLANTIC SOUTH</td>\n",
       "      <td>87</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.050</td>\n",
       "      <td>-81.1700</td>\n",
       "      <td>30.0500</td>\n",
       "      <td>-81.1700</td>\n",
       "      <td>Pre-frontal showers and thunderstorms moved so...</td>\n",
       "      <td>A brief waterspout was observed offshore of So...</td>\n",
       "      <td>87452</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202202</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>202202</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>165668</td>\n",
       "      <td>1001527</td>\n",
       "      <td>AMERICAN SAMOA</td>\n",
       "      <td>97</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-14.333</td>\n",
       "      <td>-170.7157</td>\n",
       "      <td>-14.3393</td>\n",
       "      <td>-170.7268</td>\n",
       "      <td>A surface trough over the Islands held  the po...</td>\n",
       "      <td>Over a 24-hour period, WSO Pago Pago recorded ...</td>\n",
       "      <td>97002</td>\n",
       "      <td>1440.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   BEGIN_YEARMONTH  BEGIN_DAY  BEGIN_TIME  END_YEARMONTH  END_DAY  END_TIME  \\\n",
       "0           202202         20        2118         202202       20      2218   \n",
       "1           202202         21         800         202202       22      1000   \n",
       "2           202202         22         200         202202       22       900   \n",
       "3           202202         18        1609         202202       18      1609   \n",
       "4           202202          2           0         202202        3         0   \n",
       "\n",
       "   EPISODE_ID  EVENT_ID           STATE  STATE_FIPS  ...  TOR_LENGTH  \\\n",
       "0      165464    999902          NEVADA          32  ...         0.0   \n",
       "1      165465    999903          NEVADA          32  ...         0.0   \n",
       "2      165465    999904          NEVADA          32  ...         0.0   \n",
       "3      165611   1001181  ATLANTIC SOUTH          87  ...         0.0   \n",
       "4      165668   1001527  AMERICAN SAMOA          97  ...         0.0   \n",
       "\n",
       "  TOR_WIDTH BEGIN_LAT  BEGIN_LON  END_LAT   END_LON  \\\n",
       "0       0.0       NaN        NaN      NaN       NaN   \n",
       "1       0.0       NaN        NaN      NaN       NaN   \n",
       "2       0.0       NaN        NaN      NaN       NaN   \n",
       "3       0.0    30.050   -81.1700  30.0500  -81.1700   \n",
       "4       0.0   -14.333  -170.7157 -14.3393 -170.7268   \n",
       "\n",
       "                                   EPISODE_NARRATIVE  \\\n",
       "0  Strong winds increased ahead of an approaching...   \n",
       "1  A low centered over northern and central Nevad...   \n",
       "2  A low centered over northern and central Nevad...   \n",
       "3  Pre-frontal showers and thunderstorms moved so...   \n",
       "4  A surface trough over the Islands held  the po...   \n",
       "\n",
       "                                     EVENT_NARRATIVE  ST_CT_FIPS  DURATION  \n",
       "0  Station (UP994) 3.1 SE West Wendover, Elevatio...       32033      60.0  \n",
       "1  Thirteen inches fell at station (BCSN2) Big Cr...       32037    1560.0  \n",
       "2  Fifteen inches fell at station (TJMN2) Toe Jam...       32031     420.0  \n",
       "3  A brief waterspout was observed offshore of So...       87452       0.0  \n",
       "4  Over a 24-hour period, WSO Pago Pago recorded ...       97002    1440.0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "41b84ff4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['CZ_NAME', 'SOURCE'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# WORKING, MARKDOWN UNTIL FINAL\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# drop unnecessary columns\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCZ_NAME\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSOURCE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:4957\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4809\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   4810\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   4811\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4818\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   4819\u001b[0m ):\n\u001b[1;32m   4820\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4821\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   4822\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4955\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   4956\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4957\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4958\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4959\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4960\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4961\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4962\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4963\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4964\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4965\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py:4267\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4265\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4267\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py:4311\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, consolidate, only_slice)\u001b[0m\n\u001b[1;32m   4309\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4310\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4311\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4312\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4314\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:6661\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   6660\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 6661\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6662\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   6663\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['CZ_NAME', 'SOURCE'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# WORKING, MARKDOWN UNTIL FINAL\n",
    "# drop unnecessary columns\n",
    "df.drop(['CZ_NAME', 'SOURCE'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff363f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2fe79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BEGIN_LAT'] = df['BEGIN_LAT'].replace(\"NA\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1656d020",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BEGIN_LAT'] = df['BEGIN_LAT'].astype(float)\n",
    "# df['BEGIN_LON'] = df['BEGIN_LON'].astype(float)\n",
    "# df['END_LAT'] = df['END_LAT'].astype(float)\n",
    "# df['END_LON'] = df['END_LON'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0696684a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4713d1d",
   "metadata": {},
   "source": [
    "#### write to CSV\n",
    "from pathlib import Path  \n",
    "filepath = Path('/Users/gregwelliver/Desktop/springboard_files/Severe-Weather-Repo/Data/all_storm_data5.csv')  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "df.to_csv(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945616ce",
   "metadata": {},
   "source": [
    "#### write to parquet\n",
    "parquet_file = 'example_pd.parquet'\n",
    "\n",
    "df.to_parquet(parquet_file, engine = 'pyarrow', compression = 'gzip')\n",
    "\n",
    "logging.info('Parquet file named \"%s\" has been written to disk', parquet_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3700ca6",
   "metadata": {},
   "source": [
    "#### write to parquet\n",
    "from pathlib import Path  \n",
    "filepath = Path('/Users/gregwelliver/Desktop/springboard_files/Severe-Weather-Repo/Data/all_storm_data6.pqt')  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "df.to_parquet(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66275a93",
   "metadata": {},
   "source": [
    "resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050aad81",
   "metadata": {},
   "source": [
    "CZ FIPS documentation: https://www.irsa.miami.edu/_assets/pdf/Documents/fips_statecounty_code.pdf\n",
    "\n",
    "Population density: https://covid19.census.gov/datasets/21843f238cbb46b08615fc53e19e0daf_1/explore?location=2.632620%2C0.315550%2C1.00\n",
    "\n",
    "Home price index: https://www.fhfa.gov/DataTools/Downloads/Pages/House-Price-Index-Datasets.aspx\n",
    "\n",
    "maybe useful: https://www.nar.realtor/research-and-statistics/housing-statistics/county-median-home-prices-and-monthly-mortgage-payment\n",
    "        \n",
    "land values: https://www.nass.usda.gov/Publications/Todays_Reports/reports/land0822.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d2a028",
   "metadata": {},
   "source": [
    "data that I created:\n",
    " - concatenated state and county codes for indentification\n",
    " - storm duration\n",
    " - storm distance (haven't done it yet)\n",
    " - county population density (haven't done it yet; pulled from other dataset)\n",
    " - land values ((haven't done it yet; pulled from other dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
